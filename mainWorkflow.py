# poc_run.py - Startdatei f√ºr den API-Workflow (Proof of Concept)

import logging
from services.workflow import Workflow
from dotenv import load_dotenv

# --- KONFIGURATION UND LOGGING ---
load_dotenv()
logging.basicConfig(level=logging.INFO, 
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("POC_RUN")

def main_poc():
    """
    Startet den Workflow zur Generierung eines Podcasts unter Verwendung
    der echten Gemini- und Google TTS-APIs.
    """
    logger.info("Starte ECHTEN POC des API-Workflows (LLM ‚Üí TTS)...")

    # DB-Parameter (user_id, llm_id, tts_id) werden NICHT √ºbergeben, 
    # da sie in services/workflow.py entfernt wurden.
    
    workflow = Workflow()
    
    try:
        # Hier werden nur die f√ºr die Generierung notwendigen Argumente √ºbergeben.
        audio_path = workflow.run_pipeline(
            # Erforderlich f√ºr die Skriptgenerierung
            user_prompt="Erkl√§re kurz in einfachen Worten, wie k√ºnstliche neuronale Netze funktionieren und wof√ºr sie heutzutage verwendet werden.",
            
            # Konfigurationsparameter
            thema="Neuronale Netze kurz erkl√§rt",
            dauer=1,
            sprache="de",
            hauptstimme="Max", # Wird als Dummy-Objekt an TTS √ºbergeben
            zweitstimme="Sara", # Wird als Dummy-Objekt an TTS √ºbergeben
            speakers=2
        )
        
        # Der Audio-Pfad wird von der _generate_audio Methode zur√ºckgegeben und 
        # vom Workflow am Ende protokolliert.
        logger.info(f"üéâ POC erfolgreich abgeschlossen! Die Podcast-Datei liegt unter: {audio_path}")
        
    except Exception as e:
        logger.error(f"‚ùå Der POC ist fehlgeschlagen: {e}", exc_info=True)

if __name__ == "__main__":
    main_poc()