# NOTE: LLM Service (Textgenerierung)
# Kapselt die Logik f체r die Interaktion mit Sprachmodellen (Large Language Models).
# Hier findet das Prompt Engineering statt.
#
# Einzuf체gen / Umzusetzen:
# - Klasse 'LLMService':
#   - Methode 'generate_script(prompt, language, ...)'
#   - MVP: Simuliert erst einmal nur die Antwort (Dummy-Text), um Kosten zu sparen.
#   - Sp채ter: Sendet den Prompt an die OpenAI API und gibt das bereinigte Skript zur체ck.
#   - Trennung von System-Prompt (Rollenbeschreibung) und User-Prompt.